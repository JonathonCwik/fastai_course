{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network from the ground up - Bank Fraud\n",
    "\n",
    "Based on Chapter 4 of the Fast.AI Deep Learning Book"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "from fastcore.all import *\n",
    "from fastai.data.all import *\n",
    "from pandas import *\n",
    "import numpy as np\n",
    "import torch.utils.data as data_utils\n",
    "import shutil\n",
    "import requests as req\n",
    "\n",
    "remote_url = 'https://cwikcode.com/wp-content/uploads/2022/12/data.zip'\n",
    "local_file_name = 'data.zip'\n",
    "\n",
    "# my hosting has some dumb security policy and faking a user agent seems to be the only way around it...\n",
    "data = req.get(remote_url, headers={\n",
    "    \"accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\",\n",
    "    \"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36 Edg/108.0.1462.42\"})\n",
    "with open('./data.zip', 'wb') as f:\n",
    "    f.write(data.content)\n",
    "\n",
    "print(data.status_code)\n",
    "shutil.unpack_archive(\"data.zip\", \"./\")\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "\n",
    "def normalize(x, max):\n",
    "    return x / max\n",
    "\n",
    "current_address_months_count_max = df.current_address_months_count.max()\n",
    "customer_age_max = df.customer_age.max()\n",
    "days_since_request_max = df.days_since_request.max()\n",
    "intended_balcon_amount_max = df.intended_balcon_amount.max()\n",
    "intended_balcon_amount_min = df.intended_balcon_amount.min()\n",
    "zip_count_4w_max = df.zip_count_4w.max()\n",
    "velocity_24h_max = df.velocity_24h.max()\n",
    "velocity_6h_max = df.velocity_6h.max()\n",
    "velocity_4w_max = df.velocity_4w.max()\n",
    "bank_branch_count_8w_max = df.bank_branch_count_8w.max()\n",
    "date_of_birth_distinct_emails_4w_max = df.date_of_birth_distinct_emails_4w.max()\n",
    "credit_risk_score_max = df.credit_risk_score.max()\n",
    "credit_risk_score_min = df.credit_risk_score.min()\n",
    "proposed_credit_limit_max = df.proposed_credit_limit.max()\n",
    "\n",
    "df[\"current_address_months_count\"] = df.current_address_months_count.apply(lambda x: normalize(x, current_address_months_count_max))\n",
    "df[\"customer_age\"] = df.customer_age.apply(lambda x: normalize(x, customer_age_max))\n",
    "df[\"days_since_request\"] = df.days_since_request.apply(lambda x: normalize(x, days_since_request_max))\n",
    "df[\"intended_balcon_amount\"] = df.intended_balcon_amount.apply(lambda x: normalize(x + abs(intended_balcon_amount_min), intended_balcon_amount_max + abs(intended_balcon_amount_min)))\n",
    "df[\"zip_count_4w\"] = df.zip_count_4w.apply(lambda x: normalize(x, zip_count_4w_max))\n",
    "df[\"velocity_24h\"] = df.velocity_24h.apply(lambda x: normalize(x, velocity_24h_max))\n",
    "df[\"velocity_6h\"] = df.velocity_6h.apply(lambda x: normalize(x, velocity_6h_max))\n",
    "df[\"velocity_4w\"] = df.velocity_4w.apply(lambda x: normalize(x, velocity_4w_max))\n",
    "df[\"bank_branch_count_8w\"] = df.bank_branch_count_8w.apply(lambda x: normalize(x, bank_branch_count_8w_max))\n",
    "df[\"date_of_birth_distinct_emails_4w\"] = df.date_of_birth_distinct_emails_4w.apply(lambda x: normalize(x, date_of_birth_distinct_emails_4w_max))\n",
    "df[\"credit_risk_score\"] = df.credit_risk_score.apply(lambda x: normalize(x + abs(credit_risk_score_min), credit_risk_score_max + abs(credit_risk_score_min)))\n",
    "df[\"proposed_credit_limit\"] = df.proposed_credit_limit.apply(lambda x: normalize(x, proposed_credit_limit_max))\n",
    "\n",
    "df.payment_type = df.payment_type.astype(\"category\")\n",
    "df.employment_status = df.employment_status.astype(\"category\")\n",
    "df.housing_status = df.housing_status.astype(\"category\")\n",
    "df.source = df.employment_status.astype(\"category\")\n",
    "df.device_os = df.device_os.astype(\"category\")\n",
    "df.to_csv(\"normalized.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Training and Validation DataSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 53)\n",
      "(11029, 52)\n",
      "torch.Size([800000, 52])\n"
     ]
    }
   ],
   "source": [
    "dummies = pd.get_dummies(df)\n",
    "print(dummies.shape)\n",
    "fraud = dummies[dummies.fraud_bool == 1].drop('fraud_bool', axis=1)\n",
    "not_fraud = dummies[dummies.fraud_bool == 0].drop('fraud_bool', axis=1)\n",
    "print(fraud.shape)\n",
    "\n",
    "fraud_train = fraud.sample(frac=.8, random_state=100)\n",
    "fraud_valid = fraud.drop(fraud_train.index)\n",
    "not_fraud_train = not_fraud.sample(frac=.8, random_state=100)\n",
    "not_fraud_valid = not_fraud.drop(not_fraud_train.index)\n",
    "\n",
    "train_x_t = torch.cat([torch.tensor(fraud_train.values).type(torch.FloatTensor), torch.tensor(not_fraud_train.values).type(torch.FloatTensor)])\n",
    "print(train_x_t.shape)\n",
    "train_x = train_x_t.view(-1, 52)\n",
    "train_y = tensor([1]*len(fraud_train) + [0]*len(not_fraud_train))\n",
    "dset = list(zip(train_x, train_y))\n",
    "\n",
    "valid_x = torch.cat([torch.tensor(fraud_valid.values).type(torch.FloatTensor), torch.tensor(not_fraud_valid.values).type(torch.FloatTensor)]).view(-1, 52)\n",
    "valid_y = tensor([1]*len(fraud_valid) + [0]*len(not_fraud_valid))\n",
    "valid_dset = list(zip(valid_x, valid_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6037, -0.9673, -1.5852,  0.1833,  1.3569,  2.2564,  0.0095,  0.6033,\n",
      "         0.0239, -0.4166,  0.4479, -1.9311,  0.9349, -1.0090, -0.8661,  1.2145,\n",
      "        -2.2250,  0.6223,  0.8982, -0.3833, -1.2193,  0.7720,  2.8475,  1.4876,\n",
      "         0.0376, -0.5981,  0.2384,  0.3828, -0.8168, -0.3705,  0.9810,  0.8479,\n",
      "         0.1698, -0.6509,  1.1193, -0.3699,  0.5117,  0.3170, -0.7046,  0.7504,\n",
      "        -0.8489, -1.9622,  1.4156,  0.3581, -1.5099, -0.5391,  0.2263,  0.4392,\n",
      "        -0.1941, -1.6669, -1.1988, -0.3204], requires_grad=True)\n",
      "tensor([-0.0889], requires_grad=True)\n",
      "torch.FloatTensor\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.8128, -3.0254, -1.5078,  ..., -5.3643,  0.3158,  0.7568],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_params(size, std=1.0): return (torch.randn(size)*std).type(torch.FloatTensor).requires_grad_()\n",
    "\n",
    "weights = init_params(52); print(weights)\n",
    "bias = init_params(1); print(bias)\n",
    "\n",
    "print(weights.type())\n",
    "\n",
    "def linear1(xb):\n",
    "    cross = xb@weights\n",
    "    return cross + bias\n",
    "\n",
    "preds = linear1(train_x); preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False,  ...,  True, False, False])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrects = (preds>0.0).float() == train_y\n",
    "corrects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8161349892616272"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrects.float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(preds, targets): return ((preds-targets)**2).mean().sqrt()\n",
    "\n",
    "def measure_loss(predictions, targets):\n",
    "    predictions = predictions.sigmoid()\n",
    "    return torch.where(targets==1, 1-predictions, predictions).mean()\n",
    "\n",
    "weights = init_params((52,1))\n",
    "bias = init_params(1)\n",
    "\n",
    "dl = DataLoader(dset, batch_size=512)\n",
    "xb, yb = first(dl)\n",
    "xb.shape, yb.shape\n",
    "\n",
    "valid_dl = DataLoader(valid_dset, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calc_grad(xb, yb, model):\n",
    "    preds = model(xb)\n",
    "    loss = measure_loss(preds, yb)\n",
    "    loss.backward()\n",
    "\n",
    "def train_epoch(model, lr, params):\n",
    "    for xb, yb in dl:\n",
    "        calc_grad(xb, yb, model)\n",
    "        for p in params:\n",
    "            p.data -= p.grad*lr\n",
    "            p.grad.zero_()\n",
    "\n",
    "def batch_accuracy(xb, yb):\n",
    "    preds = xb.sigmoid()\n",
    "    correct = (preds>0.5) == yb\n",
    "    return correct.float().mean()\n",
    "\n",
    "def validate_epoch(model):\n",
    "    accs = [batch_accuracy(model(xb), yb) for xb, yb in valid_dl]\n",
    "    return round(torch.stack(accs).mean().item(), 4)\n",
    "\n",
    "batch_accuracy(linear1(train_x[:12]), train_y[:12])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0758"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_epoch(linear1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.722 0.8808 0.9356 0.9587 0.9698 0.9764 0.9801 0.9824 0.984 0.9851 0.986 0.9867 0.9872 0.9875 0.9878 0.9881 0.9882 0.9884 0.9885 0.9886 "
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "params = weights, bias\n",
    "train_epoch(linear1, lr, params)\n",
    "validate_epoch(linear1)\n",
    "\n",
    "for i in range(20):\n",
    "    train_epoch(linear1, lr, params)\n",
    "    print(validate_epoch(linear1), end=' ')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>batch_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.432043</td>\n",
       "      <td>0.432598</td>\n",
       "      <td>0.988970</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.402300</td>\n",
       "      <td>0.403524</td>\n",
       "      <td>0.988970</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.372417</td>\n",
       "      <td>0.374310</td>\n",
       "      <td>0.988970</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.342293</td>\n",
       "      <td>0.344860</td>\n",
       "      <td>0.988970</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.312027</td>\n",
       "      <td>0.315276</td>\n",
       "      <td>0.988970</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.281931</td>\n",
       "      <td>0.285872</td>\n",
       "      <td>0.988970</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.252506</td>\n",
       "      <td>0.257140</td>\n",
       "      <td>0.988970</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.224351</td>\n",
       "      <td>0.229666</td>\n",
       "      <td>0.988970</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.198047</td>\n",
       "      <td>0.204016</td>\n",
       "      <td>0.988970</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.174044</td>\n",
       "      <td>0.180627</td>\n",
       "      <td>0.988970</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastai.vision.all import *\n",
    "\n",
    "simple_net = nn.Sequential(\n",
    "    nn.Linear(52, 30),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30,1)\n",
    ")\n",
    "\n",
    "dls = DataLoaders(dl, valid_dl)\n",
    "learn = Learner(dls, simple_net, opt_func=SGD, loss_func=measure_loss, metrics=batch_accuracy)\n",
    "learn.fit(10, 0.0001)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "85a3a7bfebba26730bf503b9a6d8c41e2ddf325a7dd63ef7bcaef214a69345bc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
