{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network from the ground up - Bank Fraud\n",
    "\n",
    "Based on Chapter 4 of the Fast.AI Deep Learning Book"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.all import *\n",
    "from fastai.data.all import *\n",
    "from pandas import *\n",
    "import numpy as np\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "\n",
    "def normalize(x, max):\n",
    "    return x / max\n",
    "\n",
    "current_address_months_count_max = df.current_address_months_count.max()\n",
    "customer_age_max = df.customer_age.max()\n",
    "days_since_request_max = df.days_since_request.max()\n",
    "intended_balcon_amount_max = df.intended_balcon_amount.max()\n",
    "intended_balcon_amount_min = df.intended_balcon_amount.min()\n",
    "zip_count_4w_max = df.zip_count_4w.max()\n",
    "velocity_24h_max = df.velocity_24h.max()\n",
    "velocity_6h_max = df.velocity_6h.max()\n",
    "velocity_4w_max = df.velocity_4w.max()\n",
    "bank_branch_count_8w_max = df.bank_branch_count_8w.max()\n",
    "date_of_birth_distinct_emails_4w_max = df.date_of_birth_distinct_emails_4w.max()\n",
    "credit_risk_score_max = df.credit_risk_score.max()\n",
    "credit_risk_score_min = df.credit_risk_score.min()\n",
    "proposed_credit_limit_max = df.proposed_credit_limit.max()\n",
    "\n",
    "df[\"current_address_months_count\"] = df.current_address_months_count.apply(lambda x: normalize(x, current_address_months_count_max))\n",
    "df[\"customer_age\"] = df.customer_age.apply(lambda x: normalize(x, customer_age_max))\n",
    "df[\"days_since_request\"] = df.days_since_request.apply(lambda x: normalize(x, days_since_request_max))\n",
    "df[\"intended_balcon_amount\"] = df.intended_balcon_amount.apply(lambda x: normalize(x + abs(intended_balcon_amount_min), intended_balcon_amount_max + abs(intended_balcon_amount_min)))\n",
    "df[\"zip_count_4w\"] = df.zip_count_4w.apply(lambda x: normalize(x, zip_count_4w_max))\n",
    "df[\"velocity_24h\"] = df.velocity_24h.apply(lambda x: normalize(x, velocity_24h_max))\n",
    "df[\"velocity_6h\"] = df.velocity_6h.apply(lambda x: normalize(x, velocity_6h_max))\n",
    "df[\"velocity_4w\"] = df.velocity_4w.apply(lambda x: normalize(x, velocity_4w_max))\n",
    "df[\"bank_branch_count_8w\"] = df.bank_branch_count_8w.apply(lambda x: normalize(x, bank_branch_count_8w_max))\n",
    "df[\"date_of_birth_distinct_emails_4w\"] = df.date_of_birth_distinct_emails_4w.apply(lambda x: normalize(x, date_of_birth_distinct_emails_4w_max))\n",
    "df[\"credit_risk_score\"] = df.credit_risk_score.apply(lambda x: normalize(x + abs(credit_risk_score_min), credit_risk_score_max + abs(credit_risk_score_min)))\n",
    "df[\"proposed_credit_limit\"] = df.proposed_credit_limit.apply(lambda x: normalize(x, proposed_credit_limit_max))\n",
    "\n",
    "df.payment_type = df.payment_type.astype(\"category\")\n",
    "df.employment_status = df.employment_status.astype(\"category\")\n",
    "df.housing_status = df.housing_status.astype(\"category\")\n",
    "df.source = df.employment_status.astype(\"category\")\n",
    "df.device_os = df.device_os.astype(\"category\")\n",
    "df.to_csv(\"normalized.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Training and Validation DataSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 53)\n",
      "(11029, 52)\n",
      "torch.Size([800000, 52])\n"
     ]
    }
   ],
   "source": [
    "dummies = pd.get_dummies(df)\n",
    "print(dummies.shape)\n",
    "fraud = dummies[dummies.fraud_bool == 1].drop('fraud_bool', axis=1)\n",
    "not_fraud = dummies[dummies.fraud_bool == 0].drop('fraud_bool', axis=1)\n",
    "print(fraud.shape)\n",
    "\n",
    "fraud_train = fraud.sample(frac=.8, random_state=100)\n",
    "fraud_valid = fraud.drop(fraud_train.index)\n",
    "not_fraud_train = not_fraud.sample(frac=.8, random_state=100)\n",
    "not_fraud_valid = not_fraud.drop(not_fraud_train.index)\n",
    "\n",
    "train_x_t = torch.cat([torch.tensor(fraud_train.values).type(torch.FloatTensor), torch.tensor(not_fraud_train.values).type(torch.FloatTensor)])\n",
    "print(train_x_t.shape)\n",
    "train_x = train_x_t.view(-1, 52)\n",
    "train_y = tensor([1]*len(fraud_train) + [0]*len(not_fraud_train))\n",
    "dset = list(zip(train_x, train_y))\n",
    "\n",
    "valid_x = torch.cat([torch.tensor(fraud_valid.values).type(torch.FloatTensor), torch.tensor(not_fraud_valid.values).type(torch.FloatTensor)]).view(-1, 52)\n",
    "valid_y = tensor([1]*len(fraud_valid) + [0]*len(not_fraud_valid))\n",
    "valid_dset = list(zip(valid_x, valid_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1349, -0.2689, -0.3426,  1.6692, -2.5082,  0.8137,  0.9905, -0.9003,\n",
      "        -1.8515,  1.4286,  0.8886,  0.0733, -0.7074, -1.3049, -1.3353, -0.1335,\n",
      "        -0.6165, -0.1443,  0.1219, -0.3225,  2.0532, -0.3747, -1.4065, -0.4709,\n",
      "        -0.0100, -1.4380,  1.1074,  0.8684,  0.5591, -0.0363, -0.7992, -1.0435,\n",
      "        -2.7727,  1.5963,  1.4730,  2.0461, -1.0994,  0.3424, -0.9222, -0.8537,\n",
      "         0.5174, -0.3800, -1.0286, -0.0213,  1.2814, -0.4026, -3.0598,  0.2060,\n",
      "         0.8690, -0.7434,  0.3271,  0.7673], requires_grad=True)\n",
      "tensor([0.9328], requires_grad=True)\n",
      "torch.FloatTensor\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([4.0164, 4.9184, 4.3605,  ..., 2.2637, 2.6816, 0.8623],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_params(size, std=1.0): return (torch.randn(size)*std).type(torch.FloatTensor).requires_grad_()\n",
    "\n",
    "weights = init_params(52); print(weights)\n",
    "bias = init_params(1); print(bias)\n",
    "\n",
    "print(weights.type())\n",
    "\n",
    "def linear1(xb):\n",
    "    cross = xb@weights\n",
    "    return cross + bias\n",
    "\n",
    "preds = linear1(train_x); preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True,  True,  ..., False, False, False])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrects = (preds>0.0).float() == train_y\n",
    "corrects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.048746250569820404"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrects.float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(preds, targets): return ((preds-targets)**2).mean().sqrt()\n",
    "\n",
    "def measure_loss(predictions, targets):\n",
    "    predictions = predictions.sigmoid()\n",
    "    return torch.where(targets==1, 1-predictions, predictions).mean()\n",
    "\n",
    "weights = init_params((52,1))\n",
    "bias = init_params(1)\n",
    "\n",
    "dl = DataLoader(dset, batch_size=512)\n",
    "xb, yb = first(dl)\n",
    "xb.shape, yb.shape\n",
    "\n",
    "valid_dl = DataLoader(valid_dset, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8333)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calc_grad(xb, yb, model):\n",
    "    preds = model(xb)\n",
    "    loss = measure_loss(preds, yb)\n",
    "    loss.backward()\n",
    "\n",
    "def train_epoch(model, lr, params):\n",
    "    for xb, yb in dl:\n",
    "        calc_grad(xb, yb, model)\n",
    "        for p in params:\n",
    "            p.data -= p.grad*lr\n",
    "            p.grad.zero_()\n",
    "\n",
    "def batch_accuracy(xb, yb):\n",
    "    preds = xb.sigmoid()\n",
    "    correct = (preds>0.5) == yb\n",
    "    return correct.float().mean()\n",
    "\n",
    "def validate_epoch(model):\n",
    "    accs = [batch_accuracy(model(xb), yb) for xb, yb in valid_dl]\n",
    "    return round(torch.stack(accs).mean().item(), 4)\n",
    "\n",
    "batch_accuracy(linear1(train_x[:12]), train_y[:12])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.155"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_epoch(linear1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9879 0.9881 0.9882 0.9884 0.9885 0.9885 0.9886 0.9886 0.9886 0.9887 0.9887 0.9888 0.9888 0.9888 0.9888 0.9889 0.9889 0.9889 0.9889 0.9889 "
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "params = weights, bias\n",
    "train_epoch(linear1, lr, params)\n",
    "validate_epoch(linear1)\n",
    "\n",
    "for i in range(20):\n",
    "    train_epoch(linear1, lr, params)\n",
    "    print(validate_epoch(linear1), end=' ')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>batch_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.490994</td>\n",
       "      <td>0.490455</td>\n",
       "      <td>0.723407</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.465529</td>\n",
       "      <td>0.465546</td>\n",
       "      <td>0.980727</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.439329</td>\n",
       "      <td>0.439903</td>\n",
       "      <td>0.988945</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.411961</td>\n",
       "      <td>0.413106</td>\n",
       "      <td>0.988970</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.383127</td>\n",
       "      <td>0.384863</td>\n",
       "      <td>0.988970</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.352739</td>\n",
       "      <td>0.355104</td>\n",
       "      <td>0.988970</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.321031</td>\n",
       "      <td>0.324072</td>\n",
       "      <td>0.988970</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.288605</td>\n",
       "      <td>0.292360</td>\n",
       "      <td>0.988970</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.256370</td>\n",
       "      <td>0.260867</td>\n",
       "      <td>0.988970</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.225371</td>\n",
       "      <td>0.230611</td>\n",
       "      <td>0.988970</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.196551</td>\n",
       "      <td>0.202510</td>\n",
       "      <td>0.988970</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.170578</td>\n",
       "      <td>0.177206</td>\n",
       "      <td>0.988970</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.147767</td>\n",
       "      <td>0.154998</td>\n",
       "      <td>0.988970</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.128125</td>\n",
       "      <td>0.135883</td>\n",
       "      <td>0.988970</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.111436</td>\n",
       "      <td>0.119645</td>\n",
       "      <td>0.988970</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.097366</td>\n",
       "      <td>0.105956</td>\n",
       "      <td>0.988970</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.085544</td>\n",
       "      <td>0.094454</td>\n",
       "      <td>0.988970</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.075610</td>\n",
       "      <td>0.084788</td>\n",
       "      <td>0.988970</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.067243</td>\n",
       "      <td>0.076644</td>\n",
       "      <td>0.988970</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.060167</td>\n",
       "      <td>0.069756</td>\n",
       "      <td>0.988970</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.054153</td>\n",
       "      <td>0.063900</td>\n",
       "      <td>0.988970</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.049013</td>\n",
       "      <td>0.058894</td>\n",
       "      <td>0.988970</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.044594</td>\n",
       "      <td>0.054589</td>\n",
       "      <td>0.988970</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.040773</td>\n",
       "      <td>0.050865</td>\n",
       "      <td>0.988970</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.037449</td>\n",
       "      <td>0.047625</td>\n",
       "      <td>0.988970</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.034542</td>\n",
       "      <td>0.044791</td>\n",
       "      <td>0.988970</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.031985</td>\n",
       "      <td>0.042298</td>\n",
       "      <td>0.988970</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.029725</td>\n",
       "      <td>0.040093</td>\n",
       "      <td>0.988970</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.027718</td>\n",
       "      <td>0.038135</td>\n",
       "      <td>0.988970</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.025927</td>\n",
       "      <td>0.036387</td>\n",
       "      <td>0.988970</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.024321</td>\n",
       "      <td>0.034819</td>\n",
       "      <td>0.988970</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.022876</td>\n",
       "      <td>0.033409</td>\n",
       "      <td>0.988970</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.021570</td>\n",
       "      <td>0.032134</td>\n",
       "      <td>0.988970</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.020386</td>\n",
       "      <td>0.030978</td>\n",
       "      <td>0.988970</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.019309</td>\n",
       "      <td>0.029926</td>\n",
       "      <td>0.988970</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.018326</td>\n",
       "      <td>0.028965</td>\n",
       "      <td>0.988970</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.017426</td>\n",
       "      <td>0.028086</td>\n",
       "      <td>0.988970</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.016599</td>\n",
       "      <td>0.027278</td>\n",
       "      <td>0.988970</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.015837</td>\n",
       "      <td>0.026534</td>\n",
       "      <td>0.988970</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.015135</td>\n",
       "      <td>0.025847</td>\n",
       "      <td>0.988970</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastai.vision.all import *\n",
    "\n",
    "simple_net = nn.Sequential(\n",
    "    nn.Linear(52, 30),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30,1)\n",
    ")\n",
    "\n",
    "dls = DataLoaders(dl, valid_dl)\n",
    "learn = Learner(dls, simple_net, opt_func=SGD, loss_func=measure_loss, metrics=batch_accuracy)\n",
    "learn.fit(40, 0.0001)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "85a3a7bfebba26730bf503b9a6d8c41e2ddf325a7dd63ef7bcaef214a69345bc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
